# langgraph-bot environment (aligned with langgraph-rust README; thread_id is NOT configurable, it is determined when a message arrives)

# --- LLM (OpenAI-compatible) ---
# Required for ReAct chat
OPENAI_API_KEY=your_openai_api_key_here
# Model name (optional, defaults to gpt-4o-mini)
OPENAI_MODEL=gpt-4o-mini
# API base URL (optional). OPENAI_API_BASE is also supported for compatibility.
# OPENAI_BASE_URL=https://api.openai.com/v1

# --- Embeddings / 词向量 (aligned with upstream; current langgraph-bot does not use embeddings) ---
# Optional; upstream uses OPENAI_API_KEY if not set. For semantic memory / vector search when enabled.
# EMBEDDING_API_KEY=
# Optional; upstream uses OPENAI_API_BASE / OPENAI_BASE_URL if not set
# EMBEDDING_API_BASE=https://api.openai.com/v1
# Embedding model name (upstream default: text-embedding-3-small)
# EMBEDDING_MODEL=text-embedding-3-small

# --- Checkpointer / short-term memory ---
# SQLite path for checkpoint DB; same as CLI --db default (checkpoint.db)
DB_PATH=checkpoint.db

# --- ReAct / tools ---
# Override default ReAct system prompt (optional)
# REACT_SYSTEM_PROMPT=You are a helpful assistant...
# When set, enables Exa MCP for web search (optional)
# EXA_API_KEY=your_exa_api_key_here
# Exa MCP endpoint (optional, default: https://mcp.exa.ai/mcp)
# MCP_EXA_URL=https://mcp.exa.ai/mcp
# Use HTTP to connect to Exa MCP (default: 1). Set to 0/false/no to use stdio (npx mcp-remote).
MCP_EXA_USE_HTTP=1

# --- Long-term memory (optional; USER_ID with embedding config enables semantic memory in upstream)
# USER_ID=

# --- Load command: message sources when -m/--messages is not set ---
# Path to Telegram bot SQLite (messages table); then thread_id in Load is used as chat_id
# TELEGRAM_MESSAGES_DB=./data/telegram.db
# Path to messages JSON when TELEGRAM_MESSAGES_DB is not set
# LANGGRAPH_MESSAGES_PATH=messages.json
