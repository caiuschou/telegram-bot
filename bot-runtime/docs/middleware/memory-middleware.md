# Memory Middleware

## Overview

The `MemoryMiddleware` is a middleware component that automatically manages conversation memory in the bot runtime. It saves user messages and AI responses to the memory store, retrieves relevant context for AI responses, and enables conversational continuity across sessions.

## Purpose

Memory middleware solves the following problems:

1. **Conversation Continuity**: Maintains context across multiple messages in a conversation
2. **Context Retrieval**: Provides relevant historical context to AI handlers for better responses
3. **Automatic Storage**: Automatically saves messages without requiring explicit handler code
4. **Flexible Configuration**: Supports different storage backends and retrieval strategies

## Configuration

### MemoryConfig

```rust
pub struct MemoryConfig {
    /// Memory store instance
    pub store: Arc<dyn MemoryStore>,
    /// Maximum number of recent messages to include in context
    pub max_recent_messages: usize,
    /// Maximum context tokens
    pub max_context_tokens: usize,
    /// Whether to save user messages
    pub save_user_messages: bool,
    /// Whether to save AI responses
    pub save_ai_responses: bool,
}
```

### Default Configuration

```rust
let config = MemoryConfig::default();
// - store: InMemoryVectorStore
// - max_recent_messages: 10
// - max_context_tokens: 4096
// - save_user_messages: true
// - save_ai_responses: true
```

## Usage

### Basic Usage

```rust
use bot_runtime::MemoryMiddleware;
use memory_inmemory::InMemoryVectorStore;
use std::sync::Arc;

// Create with default configuration
let store = Arc::new(InMemoryVectorStore::new());
let middleware = MemoryMiddleware::with_store(store);

// Add to handler chain
let mut chain = HandlerChain::new();
chain.add_middleware(middleware);
```

### Custom Configuration

```rust
use bot_runtime::{MemoryMiddleware, MemoryConfig};

let config = MemoryConfig {
    store: my_custom_store,
    max_recent_messages: 20,
    max_context_tokens: 8192,
    save_user_messages: true,
    save_ai_responses: false,
};

let middleware = MemoryMiddleware::new(config);
```

### Integration with Handler Chain

```rust
use bot_runtime::{HandlerChain, MemoryMiddleware, AIQueryHandler};

let mut chain = HandlerChain::new();

// Add middleware (executes before handler)
chain.add_middleware(MemoryMiddleware::with_store(store));

// Add handler
chain.add_handler(AIQueryHandler::new(ai_client));

// Process messages
chain.handle(message).await?;
```

## How It Works

### Message Processing Flow

```
1. User Message Received
   ↓
2. MemoryMiddleware::before()
   - Extract user_id and conversation_id
   - Create MemoryEntry from message
   - Save to MemoryStore
   - Return Ok(true) to continue
   ↓
3. Handler Processes Message
   - AI handler generates response
   ↓
4. MemoryMiddleware::after()
   - (TODO) Save AI response to memory
   - Currently no-op
   ↓
5. Response Sent to User
```

### Context Building

```rust
// Internally used to build context
let context = middleware
    .build_context(user_id, conversation_id)
    .await?;

// Context building uses:
// - RecentMessagesStrategy: Retrieves N most recent messages
// - UserPreferencesStrategy: Retrieves user preference entries
// - Token limit: Ensures context fits within token budget
```

### Memory Entry Structure

```rust
let entry = MemoryEntry {
    id: Uuid::new_v4(),
    content: message.content,
    embedding: None, // Generated by store
    metadata: MemoryMetadata {
        user_id: Some(message.user.id.to_string()),
        conversation_id: Some(message.chat.id.to_string()),
        role: MemoryRole::User,
        timestamp: Utc::now(),
        tokens: None,
        importance: None,
    },
};
```

## API Reference

### MemoryMiddleware

```rust
impl MemoryMiddleware {
    /// Creates a new MemoryMiddleware with given config
    pub fn new(config: MemoryConfig) -> Self;

    /// Creates a new MemoryMiddleware with default config
    pub fn with_store(store: Arc<dyn MemoryStore>) -> Self;

    /// Creates a memory entry from a bot message
    fn message_to_memory_entry(&self, message: &Message) -> MemoryEntry;

    /// Builds conversation context for a message
    async fn build_context(
        &self,
        user_id: &str,
        conversation_id: &str,
    ) -> Result<Option<String>>;
}
```

### Middleware Trait Implementation

```rust
#[async_trait]
impl Middleware for MemoryMiddleware {
    /// Saves user message to memory before handler execution
    async fn before(&self, message: &Message) -> Result<bool>;

    /// Saves AI response to memory after handler execution
    async fn after(
        &self,
        message: &Message,
        response: &HandlerResponse,
    ) -> Result<()>;
}
```

## Implementation Details

### Before Hook

The `before` hook performs the following operations:

1. Extracts `user_id` from `message.user.id`
2. Extracts `conversation_id` from `message.chat.id`
3. Creates a `MemoryEntry` with:
   - Content from message
   - User ID
   - Conversation ID
   - Role set to `MemoryRole::User`
   - Current timestamp
4. Adds entry to `MemoryStore`
5. Logs success or failure
6. Returns `Ok(true)` to allow handler execution

**Error Handling**: If saving fails, the error is logged but processing continues. This ensures that memory failures don't block message handling.

### After Hook

The `after` hook is currently a placeholder due to a limitation in `HandlerResponse`:

**Current State**: The `HandlerResponse` enum only contains variants like `Continue`, `Stop`, `Ignore` without response text.

**Required Changes**: To implement AI response saving, the AI integration must:
1. Modify `HandlerResponse` to include response text
2. Update AI handlers to return the generated response
3. Add code to save AI responses with `MemoryRole::Assistant`

### Context Building

The `build_context` method:

1. Creates a `ContextBuilder` with the configured store
2. Adds strategies:
   - `RecentMessagesStrategy`: Retrieves up to `max_recent_messages`
   - `UserPreferencesStrategy`: Retrieves user preferences
3. Sets token limit to `max_context_tokens`
4. Filters by user and conversation
5. Builds context and formats for model
6. Returns formatted context or `None` if empty

### Logging

The middleware uses `tracing` for instrumentation:

- `debug!`: Logs message processing details
- `error!`: Logs memory saving failures
- `#[instrument]`: Automatically captures function parameters in span

## Design Decisions

### Why Middleware?

Memory management is implemented as middleware because:

1. **Separation of Concerns**: Handlers focus on business logic, not memory storage
2. **Consistency**: All messages are saved automatically, no handler code needed
3. **Flexibility**: Can be enabled/disabled by adding/removing from chain
4. **Reusability**: Same middleware works across different bot configurations

### Why Continue on Save Failure?

Memory saving failures don't block message processing because:

1. **Availability**: Bot remains functional even if memory is temporarily unavailable
2. **User Experience**: Users get responses even if memory fails
3. **Observability**: Errors are logged for monitoring and debugging
4. **Graceful Degradation**: Bot can function without memory context

### Token Limit Management

Context building respects token limits to:

1. **Prevent Errors**: Avoid exceeding model context window
2. **Cost Control**: Limit tokens sent to AI models
3. **Relevance**: Prioritize recent messages within token budget

### Strategy-Based Context Retrieval

Using strategies enables:

1. **Extensibility**: Easy to add new retrieval strategies
2. **Flexibility**: Different strategies for different use cases
3. **Composition**: Multiple strategies can be combined
4. **Testing**: Each strategy can be tested independently

## Known Limitations

### AI Response Saving Not Implemented

**Issue**: The `after` hook does not save AI responses.

**Root Cause**: `HandlerResponse` enum doesn't include response text.

**Impact**: Assistant messages are not stored in memory.

**Workaround**: Manually save AI responses in handlers using `MemoryStore`.

**Planned Fix**: Modify `HandlerResponse` to include response text.

### Context Not Used

**Issue**: The `build_context` method exists but isn't automatically used.

**Root Cause**: Context building is not integrated with AI handlers.

**Impact**: AI handlers don't receive conversation context automatically.

**Workaround**: Manually build and pass context to AI handlers.

**Planned Fix**: Integrate context building with AI query handler.

## Testing

The module includes comprehensive tests:

```rust
#[test]
fn test_memory_config_default() {
    // Verifies default configuration values
}

#[test]
fn test_memory_middleware_creation() {
    // Verifies middleware instantiation
}

#[test]
fn test_message_to_memory_entry() {
    // Tests message to entry conversion
}

#[tokio::test]
async fn test_memory_middleware_saves_user_messages() {
    // Verifies user messages are saved
}

#[tokio::test]
async fn test_memory_middleware_after_handler_response() {
    // Tests after hook (currently no-op)
}

#[tokio::test]
async fn test_memory_middleware_builds_context() {
    // Tests context building
}
```

### Running Tests

```bash
cd bot-runtime
cargo test memory_middleware
```

## Future Enhancements

1. **AI Response Saving**: Implement response saving after `HandlerResponse` is updated
2. **Context Integration**: Automatically inject context into AI handlers
3. **Configurable Strategies**: Allow custom retrieval strategies
4. **Memory Pruning**: Automatic cleanup of old or low-importance entries
5. **Cross-Conversation Context**: Retrieve context from related conversations
6. **Importance Scoring**: AI-based importance scoring for better context selection

## Related Documentation

- [Memory Crate](../../../../memory/README.md) - Core memory management
- [Middleware Architecture](./README.md) - General middleware concepts
- [AI Integration](../../../../ai-integration/src/README.md) - AI handler implementation
- [RAG Solution](../../RAG_SOLUTION.md) - Overall RAG architecture
